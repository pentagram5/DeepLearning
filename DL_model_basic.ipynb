{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 폐암 수술환자의 생존율 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 데이터 셋 과 패키지 호출하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#딥러닝을 구동하는데 필요한 케라스 함수 호출 \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#실행 할때마다 같은 결과를 출력하기 위해 설정 \n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#준비된 수술 환자 데이터 불러옴\n",
    "Data_set = np.loadtxt('../Deep-Learning/dataset/ThoraricSurgery.csv', delimiter=',')\n",
    "\n",
    "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장 \n",
    "X=Data_set[:,0:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 입력층, 은닉층, 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인공 신경망 모델 만듬\n",
    "model = Sequential()\n",
    "#멤버함수 add()를 이용해 인공지능 계층 추가 - Relu\n",
    "model.add(Dense(30, input_dim = 17, activation = 'relu'))\n",
    "# 시그모이드 계층 추가 \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝이란 퍼셉트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태 이다. \n",
    "* 이층들을 Sequential() 함수를 통해 쉽게 구현할 수 있으며, model로 선언하여 model.add를 통해 새로운 라인(층)들을 추가하는 것이다. \n",
    "* 이번 모델링에서는 두개의 add로 층을 두개로 구성하엿다. \n",
    "* model.add(Dense(30, input_dim = 17, activation = 'relu')) - 첫번째 층은 30개의노드, 17개의 입력, 활성화함수는 렐루를 사용한다. -> 이말은 17개의 값을 입력받아 은닉층의 30개의 노드로 보낸다는 뜻이다. 각 노드는 17개의 입력값에서 임의의 가중치를 가지고 각 노드로 전송되어 활성화 함수인 'relu'를 만난다.\n",
    "* model.add(Dense(1, activation='sigmoid')) - 두번째 (마지막) 층은 1개의 출력, 활성화함수는 시그모이드(0,1)중 하나로 출력 \n",
    "* 따라서 첫번째 은닉층이 은닉층+입력층 역할을 겸한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 모델 컴파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#만든 모델을 어떻게 학습할지 파라미터로 지정하고 컴파일 한다. \n",
    "model.compile(loss= 'mean_squared_error', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.compile(loss= 'mean_squared_error', optimizer = 'adam', metrics=['accuracy']) - 오차함수를 mean_squared_error 로 지정. 오차를 기준으로 최적화함수(가중치조절함수) 를 'adam'( 고급경사하강법)으로 지정, metrics는 모델이 컴파일 될때 모델 의 수행 결과를 나타나게끔 설정하는 부분이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 모델 실행하기 \n",
    "* epochs => 각 샘플이 처음부터 끝가지 100번 재사용 될 때까지 실행을 반복한다.\n",
    "* batch_size -> 전체 n개의 샘플을 batch_size 만큼 끊어서 집어넣어 모델을 실행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1485 - accuracy: 0.8426\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1402 - accuracy: 0.8511\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1433 - accuracy: 0.8489\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1395 - accuracy: 0.8511\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1386 - accuracy: 0.8468\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1407 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1336 - accuracy: 0.8489\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 638us/step - loss: 0.1384 - accuracy: 0.8511\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1376 - accuracy: 0.8383\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1438 - accuracy: 0.8447\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1409 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1369 - accuracy: 0.8489\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1359 - accuracy: 0.8511\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1373 - accuracy: 0.8489\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1282 - accuracy: 0.8489\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1324 - accuracy: 0.8468\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1451 - accuracy: 0.8511\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1428 - accuracy: 0.8489\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1411 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1355 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1371 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1321 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1283 - accuracy: 0.8532\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1391 - accuracy: 0.8319\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1438 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1418 - accuracy: 0.8489\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1411 - accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1410 - accuracy: 0.8511\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1395 - accuracy: 0.8511\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1402 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 766us/step - loss: 0.1404 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1383 - accuracy: 0.8468\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1331 - accuracy: 0.8553\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1430 - accuracy: 0.8511\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1337 - accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1266 - accuracy: 0.8489\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1392 - accuracy: 0.8489\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1378 - accuracy: 0.8511\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1302 - accuracy: 0.8532\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1300 - accuracy: 0.8553\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 808us/step - loss: 0.1396 - accuracy: 0.8489\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 872us/step - loss: 0.1280 - accuracy: 0.8511\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1373 - accuracy: 0.8489\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1366 - accuracy: 0.8447\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1395 - accuracy: 0.8511\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1382 - accuracy: 0.8489\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1313 - accuracy: 0.8553\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1248 - accuracy: 0.8511\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1311 - accuracy: 0.8489\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1251 - accuracy: 0.8553\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1269 - accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1270 - accuracy: 0.8511\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1275 - accuracy: 0.8532\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1349 - accuracy: 0.8489\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1267 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1275 - accuracy: 0.8489\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1241 - accuracy: 0.8532\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1372 - accuracy: 0.8447\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1399 - accuracy: 0.8489\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1333 - accuracy: 0.8553\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1286 - accuracy: 0.8617\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1264 - accuracy: 0.8511\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 659us/step - loss: 0.1269 - accuracy: 0.8532\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1341 - accuracy: 0.8532\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1216 - accuracy: 0.8574\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1263 - accuracy: 0.8489\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1203 - accuracy: 0.8553\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 872us/step - loss: 0.1213 - accuracy: 0.8532\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1263 - accuracy: 0.8553\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1307 - accuracy: 0.8574\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1258 - accuracy: 0.8532\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1297 - accuracy: 0.8489\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1343 - accuracy: 0.8553\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1295 - accuracy: 0.8532\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1202 - accuracy: 0.8511\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1260 - accuracy: 0.8596\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1313 - accuracy: 0.8553\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1275 - accuracy: 0.8532\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1208 - accuracy: 0.8574\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1219 - accuracy: 0.8489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1276 - accuracy: 0.8553\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1248 - accuracy: 0.8596\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1197 - accuracy: 0.8553\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1344 - accuracy: 0.8404\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1344 - accuracy: 0.8532\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1284 - accuracy: 0.8511\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1242 - accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 723us/step - loss: 0.1255 - accuracy: 0.8553\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1253 - accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 702us/step - loss: 0.1189 - accuracy: 0.8574\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 638us/step - loss: 0.1200 - accuracy: 0.8596\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1340 - accuracy: 0.8511\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1202 - accuracy: 0.8553\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 744us/step - loss: 0.1228 - accuracy: 0.8553\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1197 - accuracy: 0.8596\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1216 - accuracy: 0.8553\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1221 - accuracy: 0.8574\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.1318 - accuracy: 0.8489\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1300 - accuracy: 0.8617\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 680us/step - loss: 0.1192 - accuracy: 0.8532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dc33f254a8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#오차함수 loss => 평균제곱 오차함수\n",
    "model.fit(X,Y, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 다중분류 문제 해결하기 (iris 데이터셋)\n",
    "* 세개의 품종 결과를 구분해내는 데이터셋 iris.csv를 이용해 모델링하고, 다중 분류를 해결해보자 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('../Deep-Learning/dataset/iris.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 원핫인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dataset = df.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "y_obj = dataset[:,4]\n",
    "e = LabelEncoder()\n",
    "e.fit(y_obj)\n",
    "y = e.transform(y_obj)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아이리스의 품종명으로 지정되있던 오브젝트 컬럼y를 LabelEncoder를 통해 [0,1,2]로 구분하였다. \n",
    "* 활성화 함수를 적용하기 위해선 Y값이 0,1로 구성되어 있어야 하기 때문에, tf.keras.utils.categorical()함수를 적용해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_encoded = to_categorical(y)\n",
    "y_encoded # [0,1,2,1,2,~~~]가 [[0,0,1],[[0,1,0]~~~]]으로 인코딩됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이처럼 y값(오브젝트)를 0,1로만 구성되도록 바꿔주는 기법을 원핫인코딩이라 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 소프트맥스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim = 4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최종 출력값이 3개중 하나여야 하기 때문에, 출력층에 해단하는 층의 Dense 노드 수를 3으로 설정한다 또한 ㅎ출력측 활성화 함수로 소프트맥스를 사용한다. \n",
    "* 소프트맥스는 총합이 1인 형태로 바꿔서 계산해주는 함수로, 이 값들이 교차 엔트로피를 지나 설정해둔 y오브젝트의 원핫인코딩 타입으로 레이블을 구성하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 모델 컴파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 모델 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 626us/step - loss: 1.2472 - accuracy: 0.3467\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.9901 - accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.7890 - accuracy: 0.5333\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 633us/step - loss: 0.6356 - accuracy: 0.8133\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.5382 - accuracy: 0.8533\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.4621 - accuracy: 0.9133\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 660us/step - loss: 0.4111 - accuracy: 0.9333\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.3830 - accuracy: 0.9267\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.3530 - accuracy: 0.9400\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 613us/step - loss: 0.3266 - accuracy: 0.9667\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.2992 - accuracy: 0.9467\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.2773 - accuracy: 0.9467\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.2690 - accuracy: 0.9600\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 606us/step - loss: 0.2479 - accuracy: 0.9733\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.2328 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.2234 - accuracy: 0.9600\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.2111 - accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.2099 - accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.1903 - accuracy: 0.9667\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.1822 - accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.1746 - accuracy: 0.9733\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.1716 - accuracy: 0.9600\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.1609 - accuracy: 0.9733\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.1587 - accuracy: 0.9733\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.1494 - accuracy: 0.9733\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.1418 - accuracy: 0.9800\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 633us/step - loss: 0.1439 - accuracy: 0.9800\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 633us/step - loss: 0.1227 - accuracy: 0.9933\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.1351 - accuracy: 0.9733\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 640us/step - loss: 0.1318 - accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.1255 - accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 640us/step - loss: 0.1249 - accuracy: 0.9600\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.1175 - accuracy: 0.9733\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.1163 - accuracy: 0.9600\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 646us/step - loss: 0.1152 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 633us/step - loss: 0.1134 - accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.1050 - accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.1101 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.1014 - accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 680us/step - loss: 0.1102 - accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.1002 - accuracy: 0.9733\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 580us/step - loss: 0.1025 - accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.0992 - accuracy: 0.9733\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.0971 - accuracy: 0.9733\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.1017 - accuracy: 0.9533\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.0954 - accuracy: 0.9800\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 580us/step - loss: 0.0971 - accuracy: 0.9600\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 660us/step - loss: 0.0910 - accuracy: 0.9600\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 660us/step - loss: 0.0963 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 646us/step - loss: 0.0950 - accuracy: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dc34fe24e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_encoded, epochs = 50, batch_size= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 결과 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 0.0857 - accuracy: 0.9733\n",
      "Accuracy : 0.9733\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : %.4f'%(model.evaluate(X,y_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
