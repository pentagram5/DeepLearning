{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_자연어처리_순환신경망(RNN).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOkiKVNc+HLkL+WgF+gS8JN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8DSb_BrTGAa_","colab_type":"text"},"source":["# 시퀸스 배열로 다루는 순환 신경망(RNN) \n","* 문장을 학습한다는것은, 그 의미를 전달하기 위해선 각 단어가 정해진 순서대로 입력되어야 한다.\n","* 여러 데이터가 순서와 관계없이 입력된것 것과 다르게, 과거의 입력데이터와 나중의 입력데이터 사이의 관계를 고려해야한다.\n","* 이를 해결하기 위해 순환 신경망(RNN) 방법이 고안된다. \n","* 여러 데이터가 순서대로 입력되었을대 잠시나마 앞서 입력된 데이터를 기억 해 놓는 방법. \n","* 기억된 데이터가 얼마나 중요한지를 판단해 별도의 가중치를 줘서 다음 데이터로 넘어간다. \n","* 모든 입력값에 이 작업을 순서대로 수행함으로 같은 층안에서 맴도는 성질 때문에 순환 신경망이라 한다. "]},{"cell_type":"markdown","metadata":{"id":"oPBtwYwMGulA","colab_type":"text"},"source":["##LSTM(Long Short Term Memory)\n","* 한 층 안에서 반복을 주기적으로 해야되는 RNN의 특성상, 일반 신경망보다 기울기 소실 문제가 더 발생한다.\n","* 이문제를 해결하기 위해, 다음 층으로 기억된 값을 넘길지 안넘길지 관리하는 단계가 LSTM 이다. \n"," "]},{"cell_type":"markdown","metadata":{"id":"F_tZCmpEH0A4","colab_type":"text"},"source":["## 1. LSTM을 이용해 로이터 뉴스 카테고리 분류하기 \n","* 로이터 뉴스 데이터셋 불어오기 "]},{"cell_type":"code","metadata":{"id":"FMQT6esJH8Ap","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593505184033,"user_tz":-540,"elapsed":1085,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["from keras.datasets import reuters\n","(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = 1000, test_split = 0.2)\n","#resuters 뉴스 데이터에는 토크나이저 작업을 이미 마친 데이터로, num_words 옵션은 빈도수가 1~1000번째로 높은 단어들을 불러오겠다는 옵션이다. \n","# Y_ 타겟 오브젝트에는 카테고리가 인덱스로 분류된 넘버링 데이터로 들어가게된다. "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q_hUc44FIYZo","colab_type":"text"},"source":["* 각 기사의 단어 수가 제각각 다름으로, 이를 동일하게 맞춰주는 전처리 함수 pad_sequence()를 사용해주어, 각 단어의 인덱스로 구성되어 있는 배열의 길이를 동일하게 맞춰준다. "]},{"cell_type":"code","metadata":{"id":"p-Ihe8LtIgQB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593505184457,"user_tz":-540,"elapsed":1496,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","x_train = pad_sequences(X_train, maxlen = 100)#단어수를 100개로 맞춰준다. 100개째를 넘는 단어는 버리고, 모자란 부분은 0으로 채워준다. \n","x_test = pad_sequences(X_test, maxlen = 100)\n","\n","#카테고리가 저장된 Y데이터를 카테고리걸 유틸을 통해 넘버링 해주자 \n","y_train = to_categorical(Y_train)\n","y_test = to_categorical(Y_test)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J5Zr2M2GI-HL","colab_type":"text"},"source":["* 데이터 전처리 과정이 끝났으니 딥러닝 구조를 빌드하자."]},{"cell_type":"code","metadata":{"id":"h6qZ2SBNKJlu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":745},"executionInfo":{"status":"ok","timestamp":1593505539556,"user_tz":-540,"elapsed":356586,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}},"outputId":"8fafea33-cff7-4815-a8a2-7a39e4f4298e"},"source":["\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM\n","\n","import numpy\n","import tensorflow as tf\n","import matplotlib.pyplot as plt \n","\n","seed = 0\n","numpy.random.seed(seed)\n","tf.random.set_seed(3)\n","\n","model = tf.keras.Sequential()\n","model.add(Embedding(1000,100)) #1000 -> 불러온 단어의 총 개수, 100 -> 기사당 단어갯수(패딩한 값)\n","model.add(LSTM(100, activation = 'tanh')) #LSTM레이어의 활성화 함수 -> tanh, 옵션은 기사당 단어수라 볼 수 있다. \n","model.add(Dense(46, activation = 'softmax'))# 다중분류로, 활성화함수는 softmax가 들어간다. \n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) #loss 에는 분류분제기 때문에 categorical_crossentropy\n","\n","history  = model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 100, epochs =20)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","90/90 [==============================] - 18s 199ms/step - loss: 2.5777 - accuracy: 0.3497 - val_loss: 2.1698 - val_accuracy: 0.4488\n","Epoch 2/20\n","90/90 [==============================] - 17s 194ms/step - loss: 2.0350 - accuracy: 0.4904 - val_loss: 1.9222 - val_accuracy: 0.5116\n","Epoch 3/20\n","90/90 [==============================] - 17s 193ms/step - loss: 1.9174 - accuracy: 0.4915 - val_loss: 1.8657 - val_accuracy: 0.5129\n","Epoch 4/20\n","90/90 [==============================] - 17s 193ms/step - loss: 1.7368 - accuracy: 0.5522 - val_loss: 1.7635 - val_accuracy: 0.5499\n","Epoch 5/20\n","90/90 [==============================] - 17s 194ms/step - loss: 1.6733 - accuracy: 0.5720 - val_loss: 1.6838 - val_accuracy: 0.5744\n","Epoch 6/20\n","90/90 [==============================] - 17s 194ms/step - loss: 1.6051 - accuracy: 0.5930 - val_loss: 1.6467 - val_accuracy: 0.6002\n","Epoch 7/20\n","90/90 [==============================] - 17s 194ms/step - loss: 1.5251 - accuracy: 0.6134 - val_loss: 1.5239 - val_accuracy: 0.6269\n","Epoch 8/20\n","90/90 [==============================] - 17s 193ms/step - loss: 1.3735 - accuracy: 0.6590 - val_loss: 1.4668 - val_accuracy: 0.6367\n","Epoch 9/20\n","90/90 [==============================] - 17s 194ms/step - loss: 1.2762 - accuracy: 0.6796 - val_loss: 1.3802 - val_accuracy: 0.6505\n","Epoch 10/20\n","90/90 [==============================] - 18s 195ms/step - loss: 1.1813 - accuracy: 0.6982 - val_loss: 1.3225 - val_accuracy: 0.6701\n","Epoch 11/20\n","90/90 [==============================] - 18s 195ms/step - loss: 1.1148 - accuracy: 0.7140 - val_loss: 1.2986 - val_accuracy: 0.6701\n","Epoch 12/20\n","90/90 [==============================] - 18s 194ms/step - loss: 1.0634 - accuracy: 0.7244 - val_loss: 1.2534 - val_accuracy: 0.6781\n","Epoch 13/20\n","90/90 [==============================] - 18s 195ms/step - loss: 1.0178 - accuracy: 0.7360 - val_loss: 1.2607 - val_accuracy: 0.6803\n","Epoch 14/20\n","90/90 [==============================] - 18s 195ms/step - loss: 0.9869 - accuracy: 0.7425 - val_loss: 1.2230 - val_accuracy: 0.6892\n","Epoch 15/20\n","90/90 [==============================] - 17s 194ms/step - loss: 0.9238 - accuracy: 0.7603 - val_loss: 1.2393 - val_accuracy: 0.6937\n","Epoch 16/20\n","90/90 [==============================] - 17s 193ms/step - loss: 0.8728 - accuracy: 0.7781 - val_loss: 1.2332 - val_accuracy: 0.6955\n","Epoch 17/20\n","90/90 [==============================] - 17s 194ms/step - loss: 0.8312 - accuracy: 0.7874 - val_loss: 1.2111 - val_accuracy: 0.6968\n","Epoch 18/20\n","90/90 [==============================] - 17s 194ms/step - loss: 0.8138 - accuracy: 0.7928 - val_loss: 1.2032 - val_accuracy: 0.7008\n","Epoch 19/20\n","90/90 [==============================] - 18s 194ms/step - loss: 0.7732 - accuracy: 0.8046 - val_loss: 1.2149 - val_accuracy: 0.7070\n","Epoch 20/20\n","90/90 [==============================] - 17s 193ms/step - loss: 0.7154 - accuracy: 0.8194 - val_loss: 1.2446 - val_accuracy: 0.7133\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xpRMSlKrL938","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593505540573,"user_tz":-540,"elapsed":357583,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}},"outputId":"4ddb1961-06df-49ec-be53-e30560390030"},"source":["print('\\n Test Accuracy : %.4f' %(model.evaluate(x_test, y_test)[1]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["71/71 [==============================] - 1s 19ms/step - loss: 1.2446 - accuracy: 0.7133\n","\n"," Test Accuracy : 0.7133\n"],"name":"stdout"}]}]}