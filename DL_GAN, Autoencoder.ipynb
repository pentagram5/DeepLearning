{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_GAN, Autoencoder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMPj33lUg9nCvyFSrqrFrbt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"epsFeBhwduIV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1593592537827,"user_tz":-540,"elapsed":14987,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}},"outputId":"d3e35648-7e6a-48dc-a8f9-bf709bf93792"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1dz8q2yuDx2e","colab_type":"text"},"source":["# 생성적 적대 신경망(Generative Adversarial Networks)_GAN\n","* 딥러닝의 원리를 활용해 가상의 이미지를 생성하는 알고리즘 \n","* 이미지 픽셀들을 어떻게 조합해야 우리가 생각하는 '얼굴'의 형상이 되는지를 딥러닝 알고리즘이 예측한 결과가 가상의 이미지가 된다. \n","* GAN이라는 이름에는 적대적이라는 단어가 들어가고, 알고리즘의 성격을 보여준다. \n","* 진짜 같은 '가짜'를 만들기 위해 알고리즘 내부에서 '적대적' 인 경합을 진행하기 때문. \n","* 한쪽은 가짜를 만들고, 한쪽은 진짜와 비교하는 경합의 과정을 이용한 것이 GAN의원리 "]},{"cell_type":"markdown","metadata":{"id":"NE6dy52rEw9S","colab_type":"text"},"source":["## 1.가짜 제조 공장, 생성자. \n","* 생성자(Generator)는 가상의 이미지를 만들어 내는 공장이다. \n","* 처음 랜덤한 픽셀값으로 채워진 가짜 이미지들로 시작해, 판별자의 판별결과에 따라 지속적으로 업데이트하며 점차 원하는 이미지를 만든다. \n","* DCGAN(Deep Convolution GAN) 은 최적화, 컴파일 과정이 없고, 패딩 과정이 필요하다. -> 입력과 출력의 크기를 맞추기 위해서. \n","* 입력과 출력을 맞춰야지만, 판별자가 비교할 '진짜'와 똑같은 크기가 된다. \n","* DCGAN에선  또한. 배치정규화라는 과정이 필요하다 이과정은 입력데이터의 평균이 0, 분산이 1이 되도록 재배치하는 것. \n","* 다음층으로 입력될 값을 일정하게 재배치하는 역할을 한다. 이 과정을 통해 층의 개수가 늘어나도 안정적인 학습을 진행할 수 있다. \n","* 생성자의 활성화 함수는 Relu(), 판별자로 넘기기전에는 tanh()함수를 쓴다 -> 출력 값이 -1 ~ 1 사이로 맞춰진다. "]},{"cell_type":"code","metadata":{"id":"1ZMwndvaICqA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566812,"user_tz":-540,"elapsed":1068,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","generator = Sequential()\n","generator.add(Dense(128*7*7, input_dim = 100, activation = LeakyReLU(0.2)))"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clfb4lZMMpwi","colab_type":"text"},"source":["* generator.add(Dense(128*7*7, input_dim = 100, activation = LeakyReLU(0.2)))에서 128은 임의로 정한 노드의수, 굳이 128이아니어도 충분한 노드를 마련해주면된다. Input_dim=100은 100차원 크기의 랜덤 벡터를 준비해 집어넣으라는 뜻\n","* 주의할 점은 7*7이다. 이미지의 최초크기를 말하는데 우리가 실습할 MNIST 손글씨 이미지는 28*28이다. \n","* 하지만 후에 Upsampling2D()함수로 가로 세로 크기를 2배씩 늘려주기 때문에 두번의 업셈플링을 거쳐 28*28크기로 만들어 질수 있다.\n","* 작은 크기의 이미지를 점점 키우면서 컨볼루션 레이어를 지나가게 하는 것이 DCGAN의 특징"]},{"cell_type":"code","metadata":{"id":"pb12apddNUMh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566813,"user_tz":-540,"elapsed":1053,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["generator.add(BatchNormalization())# 배치 정규화로, 다음 층에 입력될 값을 일정하게 재배치 해줌\n","generator.add(Reshape((7,7,128))) # 컨벌루션 레이어가 받아들일 수 있는 형태로 바꿔주는 코드 \n","#Conv2D()함수의 input_shape 부분에 들어가 ㄹ형태로 정해준다. "],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Leh8UZjzNxAx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566814,"user_tz":-540,"elapsed":1042,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["generator.add(UpSampling2D())#가로 세로의 픽셀단위의 크기를 두배로 늘려줌\n","generator.add(Conv2D(64, kernel_size=5, padding = 'same'))"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xfFuDKiaN-1g","colab_type":"text"},"source":["* Upsampling을 거쳐 두배씩 키워 샘플링한후. 커널 크기를 5으로해서 5*5크기의 마스크를 Conv2D함수를 거쳐 씌운다. padding = 'same' 조건으로 모자라는 부분을 자동으로 0으로 채운다. "]},{"cell_type":"code","metadata":{"id":"x2DLZuRaOPnQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566814,"user_tz":-540,"elapsed":1029,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["generator.add(BatchNormalization())# 배치 정규화로, 다음 층에 입력될 값을 일정하게 재배치 해줌\n","generator.add(Activation(LeakyReLU(0.2)))# 생성자의 활성화 함수 -> LeakyReLU\n","#GAN에서는 기존 ReLU()를 쓰면 불안정해지는 경우가 많아, 조금 변형한 LeakyReLU를 써준다. "],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jtzJKAfOnDW","colab_type":"text"},"source":["* LeakyReLU()함수는 ReLU() 함수에서 x값이 음수이면 무조건 0이 되어 뉴런들이 일찍 소실되는 단점을 보안해준다. 즉 0이하에서도 작은 값을 가지게 만드는 활성화 함수.\n","* 여기서 LeakyReLU(0.2)는 0보다 작을 경우 0.2를 곱하라는 의미"]},{"cell_type":"code","metadata":{"id":"oOq3qg3VO3qp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566815,"user_tz":-540,"elapsed":1014,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["generator.add(UpSampling2D())#가로 세로의 픽셀단위의 크기를 두배로 늘려줌\n","generator.add(Conv2D(1, kernel_size=5, padding='same', activation = 'tanh')) #판별자로 넘기기위 해 tanh사용, 값이 -1~1사이로 맞춰진다."],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XJyRIJgPEZW","colab_type":"text"},"source":["* 끝으로 한번더 배치정규화를 거치고, Conv2D() 함수를 통해 한번더 컨볼루션 을 거친후 판별자로 값을 넘길 준비를 마친다. 활성화 함수로는 tanh를 써준다. 여기까지가 생성자의 layer이다."]},{"cell_type":"markdown","metadata":{"id":"lMgmKlBBPV6v","colab_type":"text"},"source":["## 2.진위를 가려내는 장치.판별자\n","* 넘어온 이미지가 가짜인지 진짜 인지를 판별해줄 장치인 판별자(discriminator)를 만들 차례이다.\n","* 진짜(1) or 가짜(0), 둘 중 하나를 결정하는 문제이므로, 컴파일 부분은 로스함수와 최적화 함수를 그대로쓸것이다. 드롭아웃, 배치정규화, 패딩도 넣어준다.\n","* 하지만 유의할 점은 자기 자신이 학습을 해선 안된다.판별자가 얻은 가중치는 생성자로 넘겨주어 생성자가 업데이트된 이미지를 만들도록 해야한다. \n","* 따라서 판별자를 만들 때는 가중치를 저장하는 학습기능을 꺼주어야한다. "]},{"cell_type":"code","metadata":{"id":"x0K4reXMPwUq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566816,"user_tz":-540,"elapsed":1004,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size = 5, strides =2, input_shape=(28,28,1), padding ='same'))\n","#각 노드수는 64,128 개로 정할것이고 커널 크기는 5로 설정해 5*5마스크가 사용된다. input_shape은 생성자의 마지막 픽셀형태와 같다. \n","#stride 옵션은 마스크를 몇칸씩 이동시킬지 정하는 옵션 -> 가로, 세로크기가 더줄어들어 새로운 특징을 뽑아주는 효과가 있다. \n","#판별자는 업셈플링을 통해 가로 세로를 늘려주었지만, 판별자는 진짜와 가짜만 구분하면 되기때문에 그럴필요가 없다. \n","#stride나 드롭아웃, 차원을 줄여주는 기능을 적극적으로 사용해 컨벌루션 신경망 본래의 목적을 달성해주면된다. "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6ORmVHIUBbv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593592566816,"user_tz":-540,"elapsed":995,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":["discriminator.add(Activation(LeakyReLU(0.2))) #활성화 함수 ->LeakyReLU(0.2)\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding = 'same'))\n","discriminator.add(Activation(LeakyReLU(0.2))) #활성화 함수 ->LeakyReLU(0.2)\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Flatten())#로스와 시그모이드에 적용되기 위해(진짜가짜판별) 2차원을 1차원으로 바꿔주어야한다.\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n","discriminator.trainable = False #판별이 끝나고 나면 자신이 학습되지 않게끔 학습 기능을 꺼준다. "],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gk5wGUpkWsVB","colab_type":"text"},"source":["## 3.적대적 신경망(GAN) 실행하기 "]},{"cell_type":"code","metadata":{"id":"rK29XbUaWzDm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1593592567251,"user_tz":-540,"elapsed":1421,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}},"outputId":"133b999d-ca7d-484d-b527-94b2b207a3c0"},"source":["ginput = Input(shape=(100,))\n","\n","dis_output = discriminator(generator(ginput))\n","gan = Model(ginput, dis_output)\n","gan.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n","gan.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","sequential_2 (Sequential)    (None, 28, 28, 1)         865281    \n","_________________________________________________________________\n","sequential_3 (Sequential)    (None, 1)                 212865    \n","=================================================================\n","Total params: 1,078,146\n","Trainable params: 852,609\n","Non-trainable params: 225,537\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AducaxxPY7Rd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ancXvxVjv7l0u1BY5v719Q_eJfJpqebw"},"executionInfo":{"status":"ok","timestamp":1593593338282,"user_tz":-540,"elapsed":772441,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}},"outputId":"c292b07f-f22c-4869-d69d-23be96bee7bf"},"source":["# 신경망 실행시키는 함수 만들기 \n","def gan_train(epoch, batch_size, saving_interval):\n","  (X_train, _), (_,_) = mnist.load_data()\n","  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n","\n","  X_train = (X_train -127.5)/127.5\n","  true = np.ones((batch_size, 1))\n","  fake = np.zeros((batch_size, 1))\n","\n","  for i in range(epoch):\n","\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    imgs = X_train[idx]\n","    d_loss_real = discriminator.train_on_batch(imgs, true)\n","\n","    noise = np.random.normal(0,1, (batch_size,100))\n","    gen_imgs = generator.predict(noise)\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","    g_loss = gan.train_on_batch(noise, true)\n","\n","    print('epoch:%d'% i, 'd_loss:%.4f' % d_loss, 'g_loss:%.4f' % g_loss)\n","\n","    #중간과정을 이미지로 저장하는 부분 \n","    if i % saving_interval ==0:\n","      noise = np.random.normal(0,1,(25,100))\n","      gen_imgs = generator.predict(noise)\n","\n","      gen_imgs = 0.5 * gen_imgs +0.5\n","      fig, axs = plt.subplots(5,5)\n","      count = 0\n","      for j in range(5):\n","        for k in range(5):\n","          axs[j,k].imshow(gen_imgs[count,:,:,0], cmap = 'gray')\n","          axs[j,k].axis('off')\n","          count += 1\n","      \"\"\"images_dir = '/content/gdrive/My Drive/data/Mnist_GAN_image'\n","      fig.savefig(f\"{images_dir}/\\gan_mnist_%d.png\" %i)\"\"\"\n","\n","gan_train(10001,32,200)"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"vWY8oKXKa9QH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593593338285,"user_tz":-540,"elapsed":772436,"user":{"displayName":"김준연","photoUrl":"","userId":"02482623906254680950"}}},"source":[""],"execution_count":21,"outputs":[]}]}